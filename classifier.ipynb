{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbyi3e8CiE+TIRxLc/RbFj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"aTee4xDMeJuI","executionInfo":{"status":"ok","timestamp":1685536926431,"user_tz":180,"elapsed":1045,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","import itertools\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","import imutils"]},{"cell_type":"code","source":["def bottom_level(image, threshold=0.4):\n","    height, width, _ = image.shape\n","    bottle_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    bottle_gray = cv2.GaussianBlur(bottle_gray, (7, 7), 0)\n","    # cv2_imshow(bottle_gray)\n","    # plt.hist(bottle_gray.ravel(), 256,[0, 256]); plt.show()\n","    (T, bottle_threshold) = cv2.threshold(bottle_gray, 55, 255, cv2.THRESH_BINARY_INV)\n","    # cv2_imshow(bottle_threshold)\n","    contours = cv2.findContours(bottle_threshold .copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    contours = imutils.grab_contours(contours)\n","    bottle_clone = image.copy()\n","    cv2.drawContours(bottle_clone, contours, -1, (255, 0, 0), 2)\n","    # cv2_imshow(bottle_clone)\n","    areas = [cv2.contourArea(contour) for contour in contours]\n","    (contours, areas) = zip(*sorted(zip(contours, areas), key=lambda a:a[1]))\n","    # print contour with largest area\n","    bottle_clone = image.copy()\n","    cv2.drawContours(bottle_clone, [contours[-1]], -1, (255, 0, 0), 2)\n","    # cv2_imshow(bottle_clone)\n","    bottle_clone = image.copy()\n","    (x, y, w, h) = cv2.boundingRect(contours[-1])\n","    # print(f'x{x} y{y} w{w} h{h}')\n","    # print(height)\n","    aspectRatio = h / float(height)\n","    # print(aspectRatio)\n","    if aspectRatio > threshold:\n","        cv2.rectangle(bottle_clone, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","        cv2.putText(bottle_clone, \"High\", (x + 10, y + 20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n","        # cv2_imshow(bottle_clone)\n","        return True\n","    else:\n","        cv2.rectangle(bottle_clone, (x, y), (x + w, y + h), (0, 0, 255), 2)\n","        cv2.putText(bottle_clone, \"Low\", (x + 10, y + 20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n","        # cv2_imshow(bottle_clone)\n","        return False\n","    # cv2_imshow(bottle_clone)\n","   "],"metadata":{"id":"JeEpKn7SfLmW","executionInfo":{"status":"ok","timestamp":1685539093673,"user_tz":180,"elapsed":319,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def white_detector(image, threshold=0.27):\n","    lower_white = np.array([0, 0, 200])\n","    upper_white = np.array([180, 70, 255])\n","    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    mask_white = cv2.inRange(hsv_image, lower_white, upper_white)\n","    # cv2_imshow(mask_white)\n","\n","    white_segment = cv2.bitwise_and(image, image, mask=mask_white)\n","    # cv2_imshow(white_segment)\n","    \n","    total_pixels = image.shape[0] * image.shape[1]\n","    white_pixels = np.sum(mask_white) // 255\n","    white_percentage = white_pixels / total_pixels\n","    # print(white_percentage)\n","    # print(f'Percentual de branco: {white_percentage}')\n","    \n","    return white_percentage >= threshold"],"metadata":{"id":"uhwGPdYsTgrB","executionInfo":{"status":"ok","timestamp":1685538275329,"user_tz":180,"elapsed":3,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def detect_misplaced_covers(image):\n","    # cv2_imshow(image)\n","    # Preprocess the image (grayscale, blur, etc.)\n","    height, width, _ = image.shape\n","    cover_line = image[:height//2, :]\n","    # cv2_imshow(cover_line)\n","\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    blurred = cv2.GaussianBlur(gray, (5,5), 0)\n","    # cv2_imshow(blurred)\n","\n","    threshold1 = 50\n","    threshold2 = 100\n","    rho = 1\n","    theta = np.pi/180\n","    threshold = 51\n","\n","    # Apply Canny edge detection\n","    edges = cv2.Canny(blurred, threshold1, threshold2)\n","    # cv2_imshow(edges)\n","\n","    # Perform the Hough transform to detect lines\n","    lines = cv2.HoughLines(edges, rho, theta, threshold)\n","    green_lines = 0  # Counter for horizontal lines\n","    blue_lines = 0\n","    ignored_lines = 0  # Counter for line intersections\n","    perfectlyPlaced = False\n","\n","    max_horizontal_threshold = 95*np.pi/180\n","    min_horizontal_threshold = 10*np.pi/180\n","    vertical_lines = []\n","    lineData = []\n"," \n","    if lines is not None:\n","        image_with_lines = image.copy()\n","        for line in lines:\n","            rho, theta = line[0]\n","            cos_theta = np.cos(theta)\n","            sin_theta = np.sin(theta)\n","            angle_diff = np.abs(theta - 0) #delete this\n","            x0 = cos_theta * rho\n","            y0 = sin_theta * rho\n","            pt1 = (int(x0 + 1000 * (-sin_theta)), int(y0 + 1000 * (cos_theta)))\n","            pt2 = (int(x0 - 1000 * (-sin_theta)), int(y0 - 1000 * (cos_theta)))\n","            # cv2.line(image_with_lines, pt1, pt2, (0, 255, 0), 2)\n","            if  (theta >= 0 and theta <=  3*np.pi/180):\n","              color = (0, 255, 255)\n","              ignored_lines += 1\n","              lineData.append([theta, 'ignorado'])\n","            elif (theta >= 178*np.pi/180 and theta <=  182*np.pi/180):\n","              color = (0, 255, 255)\n","              ignored_lines += 1\n","              lineData.append([theta, 'ignorado'])\n","            elif (theta < max_horizontal_threshold and theta > min_horizontal_threshold):\n","              lineData.append([theta, 'horizontal'])\n","              # print(theta, 'horizontal')\n","              color = (0, 255, 0)\n","              green_lines += 1\n","            else:\n","              lineData.append([theta, 'n passou'])\n","              color = (255, 0 , 0)\n","              vertical_lines.append(line)\n","              blue_lines += 1\n","              # cv2.line(image_with_lines, pt1, pt2, (0, 255, 0), 2)\n","\n","            cv2.line(image_with_lines, pt1, pt2, color, 2)\n","        # cv2_imshow(image_with_lines)\n","        if green_lines >= blue_lines or ignored_lines == len(lines) or len(lines) == 0:\n","          perfectlyPlaced = True\n","        else:\n","            # cv2_imshow(blurred)\n","            # cv2_imshow(edges)\n","            # for data in lineData:\n","            #   print(data)\n","            # cv2_imshow(image_with_lines)\n","            perfectlyPlaced = False\n","            # print(perfectlyPlaced)\n","    # else:\n","    #   cv2_imshow(blurred)\n","    #   cv2_imshow(edges)\n","    # for data in lineData:\n","    #     print(data)\n","    # cv2_imshow(image_with_lines)\n","    # print(perfectlyPlaced)\n","    return perfectlyPlaced"],"metadata":{"id":"EIE9HFonMjM8","executionInfo":{"status":"ok","timestamp":1685538275329,"user_tz":180,"elapsed":2,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def black_detector(image, threshold = 0.135):\n","    bottle_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    bottle_gray = cv2.GaussianBlur(bottle_gray, (7, 7), 0)\n","    (T, bottle_threshold) = cv2.threshold(bottle_gray, 55, 255, cv2.THRESH_BINARY_INV)\n","    black_segment = cv2.bitwise_and(image, image, mask=bottle_threshold)\n","    # cv2_imshow(black_segment)\n","\n","    total_pixels = image.shape[0] * image.shape[1]\n","    black_pixels = np.sum(bottle_threshold) // 255\n","    black_percentage = black_pixels / total_pixels\n","    # print(f'Percentual de preto: {black_percentage}')\n","\n","    return black_percentage >= threshold"],"metadata":{"id":"cJF-eqVzvG7b","executionInfo":{"status":"ok","timestamp":1685538276420,"user_tz":180,"elapsed":2,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def red_detector(image, threshold=0.4):\n","    #label 40%\n","    #cover ?\n","    lower_red1 = np.array([0, 70, 50])\n","    upper_red1 = np.array([10, 255, 255])\n","    lower_red2 = np.array([170, 70, 50])\n","    upper_red2 = np.array([180, 255, 255])\n","\n","    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    mask_red1 = cv2.inRange(hsv_image, lower_red1, upper_red1)\n","    mask_red2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n","    mask_red = cv2.bitwise_or(mask_red1, mask_red2)\n","    # cv2_imshow(mask_red)\n","\n","    red_segment = cv2.bitwise_and(image, image, mask=mask_red)\n","    # cv2_imshow(red_segment)\n","\n","    total_pixels = image.shape[0] * image.shape[1]\n","    red_pixels = np.sum(mask_red) // 255\n","\n","    red_percentage = red_pixels / total_pixels\n","    # print(red_percentage)\n","    # print(f'Percentual de vermelho: {red_percentage}')\n","    return red_percentage >= threshold"],"metadata":{"id":"ySmxp2A_P7zX","executionInfo":{"status":"ok","timestamp":1685538276748,"user_tz":180,"elapsed":2,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def handler_bottom(img):\n","  height, width, _ = img.shape\n","  response = np.zeros(8)\n","\n","  # Calculate the length of each part\n","  part_length = width // 3\n","\n","  # Divide the image into three parts\n","  bottle1 = img[:, :part_length]\n","  bottle2 = img[:, part_length:2*part_length]\n","  bottle3 = img[:, 2*part_length:]\n","\n","  cap1 = bottle1[:height//5, :]\n","  cap2 = bottle2[:height//5, :]\n","  cap3 = bottle3[:height//5, :]\n","\n","  cover1 = bottle1[170:305,:]\n","  cover2 = bottle2[170:305,:]\n","  cover3 = bottle3[170:305,:]\n","\n","  neck1 = bottle1[40:185,:]\n","  neck2 = bottle2[40:185,:]\n","  neck3 = bottle3[40:185,:]\n","\n","  filled = black_detector(neck2)\n","  capped = red_detector(cap2, threshold=0.3)\n","  redCover =  red_detector(cover2)\n","  whiteCover = white_detector(cover2)\n","  covered = redCover or whiteCover\n","  unlabeled = black_detector(cover2, threshold=0.42)\n","\n","  if filled or capped or covered:\n","    if not capped:\n","      response[2] = 1 \n","    if whiteCover:\n","      response[4] = 1 \n","    if unlabeled:\n","      response[6] = 1 \n","    # print(f'Tem tampa? {capped}')\n","    # print(f'Embalagem Vermelha? {redCover}')\n","    # print(f'Embalagem branca? {whiteCover}')\n","    # print(f'Sem embalagem? {unlabeled}')\n","    if not unlabeled:\n","      if not detect_misplaced_covers(cover2):\n","        response[5] = 1 \n","      # print(f'Embalagem posicionada corretamente? {detect_misplaced_covers(cover2)}')\n","    if filled:\n","      if bottom_level(neck2):\n","        # print('Nivel Alto')\n","        response[0] = 1\n","    else:\n","      # response[0] = 0\n","      response[1] = 1\n","      # print('Nivel Baixo')\n","  else:\n","    response[7] = 1\n","    # print('Sem garrafa')\n","\n","  return response"],"metadata":{"id":"OeKhTymaQuKN","executionInfo":{"status":"ok","timestamp":1685539069674,"user_tz":180,"elapsed":739,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["for i in range(1, 78):\n","  image = cv2.imread(f'train_{i}.jpg')\n","  print(f'train_{i}.jpg')\n","  print(handler_bottom(image))\n","  # image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  # plt.imshow(image_rgb)\n","  # plt.axis('off')  # Optional: Turn off axis labels\n","  # plt.show()\n","  # print('--------------------------------------')\n","  print()"],"metadata":{"id":"a0j9cZnzZSfX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685539103968,"user_tz":180,"elapsed":819,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}},"outputId":"51223b3d-2901-4a4c-90de-cecf3121ab0f"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["train_1.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_2.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_3.jpg\n","[1. 0. 1. 0. 0. 1. 0. 0.]\n","\n","train_4.jpg\n","[1. 0. 1. 0. 0. 0. 0. 0.]\n","\n","train_5.jpg\n","[1. 0. 1. 0. 0. 0. 0. 0.]\n","\n","train_6.jpg\n","[1. 0. 1. 0. 0. 0. 0. 0.]\n","\n","train_7.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_8.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_9.jpg\n","[0. 0. 0. 0. 0. 0. 0. 1.]\n","\n","train_10.jpg\n","[1. 0. 0. 0. 0. 1. 0. 0.]\n","\n","train_11.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_12.jpg\n","[1. 0. 1. 0. 0. 0. 0. 0.]\n","\n","train_13.jpg\n","[0. 0. 0. 0. 0. 0. 0. 1.]\n","\n","train_14.jpg\n","[0. 0. 0. 0. 0. 0. 1. 0.]\n","\n","train_15.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_16.jpg\n","[0. 0. 0. 0. 1. 0. 0. 0.]\n","\n","train_17.jpg\n","[0. 1. 1. 0. 0. 0. 0. 0.]\n","\n","train_18.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_19.jpg\n","[1. 0. 0. 0. 0. 1. 0. 0.]\n","\n","train_20.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_21.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_22.jpg\n","[0. 1. 0. 0. 0. 0. 0. 0.]\n","\n","train_23.jpg\n","[1. 0. 1. 0. 0. 0. 1. 0.]\n","\n","train_24.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_25.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_26.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_27.jpg\n","[1. 0. 1. 0. 0. 0. 0. 0.]\n","\n","train_28.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_29.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_30.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_31.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_32.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_33.jpg\n","[1. 0. 0. 0. 0. 1. 0. 0.]\n","\n","train_34.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_35.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_36.jpg\n","[0. 0. 0. 0. 0. 0. 1. 0.]\n","\n","train_37.jpg\n","[0. 0. 0. 0. 0. 0. 0. 1.]\n","\n","train_38.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_39.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_40.jpg\n","[0. 0. 0. 0. 1. 0. 0. 0.]\n","\n","train_41.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_42.jpg\n","[1. 0. 1. 0. 0. 0. 0. 0.]\n","\n","train_43.jpg\n","[0. 0. 0. 0. 1. 0. 0. 0.]\n","\n","train_44.jpg\n","[0. 1. 0. 0. 0. 0. 0. 0.]\n","\n","train_45.jpg\n","[0. 0. 0. 0. 1. 0. 0. 0.]\n","\n","train_46.jpg\n","[0. 1. 0. 0. 0. 0. 0. 0.]\n","\n","train_47.jpg\n","[1. 0. 0. 0. 0. 1. 0. 0.]\n","\n","train_48.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_49.jpg\n","[0. 1. 0. 0. 0. 0. 0. 0.]\n","\n","train_50.jpg\n","[0. 1. 0. 0. 0. 0. 0. 0.]\n","\n","train_51.jpg\n","[1. 0. 0. 0. 0. 1. 0. 0.]\n","\n","train_52.jpg\n","[0. 1. 0. 0. 0. 0. 0. 0.]\n","\n","train_53.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_54.jpg\n","[0. 0. 0. 0. 0. 0. 1. 0.]\n","\n","train_55.jpg\n","[0. 1. 0. 0. 0. 0. 0. 0.]\n","\n","train_56.jpg\n","[0. 0. 0. 0. 1. 0. 0. 0.]\n","\n","train_57.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_58.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_59.jpg\n","[0. 0. 0. 0. 0. 0. 0. 1.]\n","\n","train_60.jpg\n","[0. 0. 0. 0. 0. 0. 1. 0.]\n","\n","train_61.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_62.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_63.jpg\n","[0. 0. 0. 0. 1. 0. 0. 0.]\n","\n","train_64.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_65.jpg\n","[0. 0. 0. 0. 0. 0. 0. 1.]\n","\n","train_66.jpg\n","[0. 0. 0. 0. 0. 0. 0. 1.]\n","\n","train_67.jpg\n","[1. 0. 0. 0. 1. 0. 0. 0.]\n","\n","train_68.jpg\n","[0. 0. 0. 0. 0. 0. 1. 0.]\n","\n","train_69.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_70.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_71.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_72.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_73.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_74.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_75.jpg\n","[1. 0. 0. 0. 0. 0. 0. 0.]\n","\n","train_76.jpg\n","[1. 0. 0. 0. 0. 1. 0. 0.]\n","\n","train_77.jpg\n","[0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]}]},{"cell_type":"code","source":["sample = cv2.imread(f'train_10.jpg')\n","handler_bottom(sample)"],"metadata":{"id":"Be1_F_VRcLKw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685498567897,"user_tz":180,"elapsed":3,"user":{"displayName":"Anderson Clemente","userId":"08463463128639858858"}},"outputId":"7c137d22-b700-418f-ada7-69b04dba72ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Percentual de preto: 0.26790450928381965\n","Percentual de vermelho: 0.36857100014994754\n","Percentual de vermelho: 0.6479791395045632\n","Percentual de branco: 0.0950311458786035\n","Percentual de preto: 0.13197160654787773\n","Tem tampa? True\n","Embalagem Vermelha? True\n","Embalagem branca? False\n","Sem embalagem? False\n","Embalagem posicionada corretamente? False\n","Nivel Alto\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"L8EYN0UoE_8m"},"execution_count":null,"outputs":[]}]}